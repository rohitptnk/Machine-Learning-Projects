{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2"
      ],
      "metadata": {
        "id": "uqkRA94q5yQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3S2zHPusL71",
        "outputId": "f900176a-ff0e-414d-bfd7-9e6059335053"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the dataset**"
      ],
      "metadata": {
        "id": "WQy4KnNS6BU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/hate/train.csv\n",
        "!wget https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/hate/val.csv\n",
        "!wget https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/humor/train.csv\n",
        "!wget https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/humor/val.csv\n",
        "!wget https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/sarcasm/train.csv\n",
        "!wget https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/sarcasm/val.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMMEwDUFrY0R",
        "outputId": "63609b6e-3b04-4e4e-dfd4-bf6b09514eb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-04 16:41:38--  https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/hate/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 406615 (397K) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>] 397.08K  2.03MB/s    in 0.2s    \n",
            "\n",
            "2025-04-04 16:41:39 (2.03 MB/s) - ‘train.csv’ saved [406615/406615]\n",
            "\n",
            "--2025-04-04 16:41:39--  https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/hate/val.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49821 (49K) [text/plain]\n",
            "Saving to: ‘val.csv’\n",
            "\n",
            "val.csv             100%[===================>]  48.65K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-04-04 16:41:39 (891 KB/s) - ‘val.csv’ saved [49821/49821]\n",
            "\n",
            "--2025-04-04 16:41:39--  https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/humor/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 192093 (188K) [text/plain]\n",
            "Saving to: ‘train.csv.1’\n",
            "\n",
            "train.csv.1         100%[===================>] 187.59K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-04-04 16:41:40 (1.23 MB/s) - ‘train.csv.1’ saved [192093/192093]\n",
            "\n",
            "--2025-04-04 16:41:40--  https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/humor/val.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23964 (23K) [text/plain]\n",
            "Saving to: ‘val.csv.1’\n",
            "\n",
            "val.csv.1           100%[===================>]  23.40K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2025-04-04 16:41:41 (2.51 MB/s) - ‘val.csv.1’ saved [23964/23964]\n",
            "\n",
            "--2025-04-04 16:41:41--  https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/sarcasm/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 472095 (461K) [text/plain]\n",
            "Saving to: ‘train.csv.2’\n",
            "\n",
            "train.csv.2         100%[===================>] 461.03K  2.26MB/s    in 0.2s    \n",
            "\n",
            "2025-04-04 16:41:42 (2.26 MB/s) - ‘train.csv.2’ saved [472095/472095]\n",
            "\n",
            "--2025-04-04 16:41:42--  https://raw.githubusercontent.com/islnlp/Assignment_1_2025/refs/heads/main/sarcasm/val.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58401 (57K) [text/plain]\n",
            "Saving to: ‘val.csv.2’\n",
            "\n",
            "val.csv.2           100%[===================>]  57.03K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-04-04 16:41:43 (967 KB/s) - ‘val.csv.2’ saved [58401/58401]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rohitptnk/Machine-Learning-Projects/raw/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn.keras\n",
        "!wget https://github.com/rohitptnk/Machine-Learning-Projects/raw/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn1.keras\n",
        "!wget https://github.com/rohitptnk/Machine-Learning-Projects/raw/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn2.keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h_sVUdk9UQl",
        "outputId": "2d8ad21a-82e3-473c-b0ce-2f026f6e4000"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-04 18:02:02--  https://github.com/rohitptnk/Machine-Learning-Projects/raw/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn.keras\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rohitptnk/Machine-Learning-Projects/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn.keras [following]\n",
            "--2025-04-04 18:02:03--  https://raw.githubusercontent.com/rohitptnk/Machine-Learning-Projects/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn.keras\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8557331 (8.2M) [application/octet-stream]\n",
            "Saving to: ‘best_model_ffnn.keras.1’\n",
            "\n",
            "best_model_ffnn.ker 100%[===================>]   8.16M  20.7MB/s    in 0.4s    \n",
            "\n",
            "2025-04-04 18:02:04 (20.7 MB/s) - ‘best_model_ffnn.keras.1’ saved [8557331/8557331]\n",
            "\n",
            "--2025-04-04 18:02:05--  https://github.com/rohitptnk/Machine-Learning-Projects/raw/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn1.keras\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rohitptnk/Machine-Learning-Projects/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn1.keras [following]\n",
            "--2025-04-04 18:02:05--  https://raw.githubusercontent.com/rohitptnk/Machine-Learning-Projects/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn1.keras\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6138482 (5.9M) [application/octet-stream]\n",
            "Saving to: ‘best_model_ffnn1.keras.1’\n",
            "\n",
            "best_model_ffnn1.ke 100%[===================>]   5.85M  15.2MB/s    in 0.4s    \n",
            "\n",
            "2025-04-04 18:02:06 (15.2 MB/s) - ‘best_model_ffnn1.keras.1’ saved [6138482/6138482]\n",
            "\n",
            "--2025-04-04 18:02:07--  https://github.com/rohitptnk/Machine-Learning-Projects/raw/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn2.keras\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rohitptnk/Machine-Learning-Projects/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn2.keras [following]\n",
            "--2025-04-04 18:02:07--  https://raw.githubusercontent.com/rohitptnk/Machine-Learning-Projects/refs/heads/main/NLP%20Assignments/Assignment%202/best_model_ffnn2.keras\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7512848 (7.2M) [application/octet-stream]\n",
            "Saving to: ‘best_model_ffnn2.keras.1’\n",
            "\n",
            "best_model_ffnn2.ke 100%[===================>]   7.16M  18.5MB/s    in 0.4s    \n",
            "\n",
            "2025-04-04 18:02:08 (18.5 MB/s) - ‘best_model_ffnn2.keras.1’ saved [7512848/7512848]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "14QjhxXYrVoP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Embedding,\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Bidirectional,\n",
        "    SimpleRNN,\n",
        "    Input,\n",
        "    Concatenate,\n",
        "    Dropout\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam, AdamW, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import BinaryFocalCrossentropy, CategoricalCrossentropy\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import keras_tuner as kt\n",
        "from keras_tuner import RandomSearch, Objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yBTH1GFgrVoR"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.expand_frame_repr', False)"
      ],
      "metadata": {
        "id": "3A_OmIQoWMRT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "o9O1tlJtrVoR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "327b4a30-d1e5-443c-ab8d-86a4ca341fb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                Sentence  Tag\n",
              "3281  Kiran kher ji ki khud ki beti Ka rape hota to bhi yahi bayan deti vo! Samjhe! BJP Raj me hua rape bhi deshhit me aur Rashtrawadi rape hota Hai Hai yar, samjhte nahi tum. #KyunkiSharmInheAatiNahi    1\n",
              "3150                                                         Yeh sab hindu satan mei hota hy. Bus mei rape. Rickshaw mei rape. Baap beti ko bech k paisay kamata hy. Larki Ki padaish py usko zameen mei    1\n",
              "1595                                                                        baise hi hai kai si aurto ka rape krte waqt jai sri raam bolna  aur jo allah hu akbar bol ke jaan leta hai bo islam nahi hai    0\n",
              "2583                                                                                                                                                                isi waja se aaj itna hate mila mujhe    0\n",
              "2710                                                                                           Sab se pehle qanoon vevastha darustha kijye kiy aapne bajrangyon gundagardi aur juned ka murder ni dekha?    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2893f5b0-7aba-49aa-afe1-6bcb49f5b141\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3281</th>\n",
              "      <td>Kiran kher ji ki khud ki beti Ka rape hota to bhi yahi bayan deti vo! Samjhe! BJP Raj me hua rape bhi deshhit me aur Rashtrawadi rape hota Hai Hai yar, samjhte nahi tum. #KyunkiSharmInheAatiNahi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3150</th>\n",
              "      <td>Yeh sab hindu satan mei hota hy. Bus mei rape. Rickshaw mei rape. Baap beti ko bech k paisay kamata hy. Larki Ki padaish py usko zameen mei</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>baise hi hai kai si aurto ka rape krte waqt jai sri raam bolna  aur jo allah hu akbar bol ke jaan leta hai bo islam nahi hai</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>isi waja se aaj itna hate mila mujhe</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>Sab se pehle qanoon vevastha darustha kijye kiy aapne bajrangyon gundagardi aur juned ka murder ni dekha?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2893f5b0-7aba-49aa-afe1-6bcb49f5b141')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2893f5b0-7aba-49aa-afe1-6bcb49f5b141 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2893f5b0-7aba-49aa-afe1-6bcb49f5b141');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67cf011d-ff1d-4b7d-ae70-365e01c39438\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67cf011d-ff1d-4b7d-ae70-365e01c39438')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67cf011d-ff1d-4b7d-ae70-365e01c39438 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Yeh sab hindu satan mei hota hy. Bus mei rape. Rickshaw mei rape. Baap beti ko bech k paisay kamata hy. Larki Ki padaish py usko zameen mei\",\n          \"Sab se pehle qanoon vevastha darustha kijye kiy aapne bajrangyon gundagardi aur juned ka murder ni dekha?\",\n          \"baise hi hai kai si aurto ka rape krte waqt jai sri raam bolna  aur jo allah hu akbar bol ke jaan leta hai bo islam nahi hai\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/val.csv')\n",
        "\n",
        "texts = train_data['Sentence'].values\n",
        "labels = train_data['Tag'].values\n",
        "\n",
        "train_data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!git clone https://github.com/rohitptnk/Machine-Learning-Projects.git\n",
        "%cd Machine-Learning-Projects/NLP\\ Assignments/Assignment\\ 2'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AO0Zqy3trvE1",
        "outputId": "82dda45d-7b11-467a-d889-f6d1d9995f88"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!git clone https://github.com/rohitptnk/Machine-Learning-Projects.git\\n%cd Machine-Learning-Projects/NLP\\\\ Assignments/Assignment\\\\ 2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre-processing**"
      ],
      "metadata": {
        "id": "ZXPzhJzH6Tcl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "92QJt-xvrVoR"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "texts_preprocessed = [preprocess_text(text) for text in texts]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts_preprocessed)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(texts_preprocessed)\n",
        "\n",
        "max_sequence_len = 128\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "T4cJIsdprVoS",
        "outputId": "50179458-beb0-4ab5-9171-43a0a2b94bbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def generate_skipgram_pairs(sentences, window_size, vocab_size):\\n    skipgrams = []\\n\\n    for sentence in sentences:\\n        for i, word in enumerate(sentence):\\n            if word not in tokenizer.word_index:\\n                continue\\n\\n            target_word = tokenizer.word_index[word]\\n\\n            context_window = sentence[max(i - window_size, 0): min(i + window_size + 1, len(sentence))]\\n\\n            for context_word in context_window:\\n                if context_word != word and context_word in tokenizer.word_index:\\n                    context_word_idx = tokenizer.word_index[context_word]\\n                    skipgrams.append([target_word, context_word_idx])\\n\\n    return np.array(skipgrams)\\n\\n\\nskipgrams = generate_skipgram_pairs(sentences, window_size, vocab_size)\\n\\n\\nX_target, X_context = zip(*skipgrams)\\nX_target = np.array(X_target)\\nX_context = np.array(X_context)\\n\\ninput_target = tf.keras.layers.Input(shape=(1,))\\ninput_context = tf.keras.layers.Input(shape=(1,))\\n\\n# Embedding layer for target and context\\nembedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name=\"embedding\")\\ntarget_embedding = embedding(input_target)\\ncontext_embedding = embedding(input_context)\\n\\ntarget_embedding = tf.keras.layers.Reshape((embedding_dim,))(target_embedding)\\ncontext_embedding = tf.keras.layers.Reshape((embedding_dim,))(context_embedding)\\n\\n# cosine similarity between target and context\\ndot_product = tf.keras.layers.Dot(axes=1)([target_embedding, context_embedding])\\noutput = tf.keras.layers.Dense(1, activation=\\'sigmoid\\')(dot_product)\\n\\nword2vec_model = tf.keras.Model(inputs=[input_target, input_context], outputs=output)\\nword2vec_model.compile(optimizer=\\'adam\\', loss=\\'binary_crossentropy\\')\\n\\nlabels = np.ones((len(skipgrams), 1))\\nword2vec_model.fit([X_target, X_context], labels, epochs=10, batch_size=128)\\ntrained_embeddings = word2vec_model.get_layer(\\'embedding\\').get_weights()[0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "sentences = [text.split() for text in texts_preprocessed]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "embedding_dim = 100\n",
        "window_size = 5\n",
        "\n",
        "'''def generate_skipgram_pairs(sentences, window_size, vocab_size):\n",
        "    skipgrams = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for i, word in enumerate(sentence):\n",
        "            if word not in tokenizer.word_index:\n",
        "                continue\n",
        "\n",
        "            target_word = tokenizer.word_index[word]\n",
        "\n",
        "            context_window = sentence[max(i - window_size, 0): min(i + window_size + 1, len(sentence))]\n",
        "\n",
        "            for context_word in context_window:\n",
        "                if context_word != word and context_word in tokenizer.word_index:\n",
        "                    context_word_idx = tokenizer.word_index[context_word]\n",
        "                    skipgrams.append([target_word, context_word_idx])\n",
        "\n",
        "    return np.array(skipgrams)\n",
        "\n",
        "\n",
        "skipgrams = generate_skipgram_pairs(sentences, window_size, vocab_size)\n",
        "\n",
        "\n",
        "X_target, X_context = zip(*skipgrams)\n",
        "X_target = np.array(X_target)\n",
        "X_context = np.array(X_context)\n",
        "\n",
        "input_target = tf.keras.layers.Input(shape=(1,))\n",
        "input_context = tf.keras.layers.Input(shape=(1,))\n",
        "\n",
        "# Embedding layer for target and context\n",
        "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name=\"embedding\")\n",
        "target_embedding = embedding(input_target)\n",
        "context_embedding = embedding(input_context)\n",
        "\n",
        "target_embedding = tf.keras.layers.Reshape((embedding_dim,))(target_embedding)\n",
        "context_embedding = tf.keras.layers.Reshape((embedding_dim,))(context_embedding)\n",
        "\n",
        "# cosine similarity between target and context\n",
        "dot_product = tf.keras.layers.Dot(axes=1)([target_embedding, context_embedding])\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(dot_product)\n",
        "\n",
        "word2vec_model = tf.keras.Model(inputs=[input_target, input_context], outputs=output)\n",
        "word2vec_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "labels = np.ones((len(skipgrams), 1))\n",
        "word2vec_model.fit([X_target, X_context], labels, epochs=10, batch_size=128)\n",
        "trained_embeddings = word2vec_model.get_layer('embedding').get_weights()[0]'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save('word2vec_embeddings.npy', trained_embeddings)"
      ],
      "metadata": {
        "id": "wdje_Gbcbgwp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Lo83GuOqrVoS"
      },
      "outputs": [],
      "source": [
        "# trained_embeddings = np.load('word2vec_embeddings.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "towm2lPSrVoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6e2b0c33-dd4e-4011-8eda-05fa2ef8190f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"X = pad_sequences(sequences, maxlen=max_sequence_len)\\nlabels = train_data['Tag'].values\\n\\nX_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.1, random_state=60)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "'''X = pad_sequences(sequences, maxlen=max_sequence_len)\n",
        "labels = train_data['Tag'].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.1, random_state=60)'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "YdSO8ka-rVoT"
      },
      "outputs": [],
      "source": [
        "test_texts = test_data['Sentence'].values\n",
        "test_texts_preprocessed = [preprocess_text(text) for text in test_texts]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts_preprocessed)\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_sequence_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Jgl4FvHMrVoT"
      },
      "outputs": [],
      "source": [
        "# custom macro F1 score function\n",
        "def macro_f1_score(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    y_pred_bin = tf.round(y_pred)\n",
        "\n",
        "    def f1(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "        f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "        return f1_val\n",
        "\n",
        "    f1_per_class = f1(y_true, y_pred_bin)\n",
        "    return K.mean(f1_per_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hBBspwjRrVoU",
        "outputId": "4e7cac3d-a2a7-4e99-d1e3-889c2bd5dff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def build_model(hp):\\n    model = Sequential()\\n\\n    embedding_dim = 100\\n\\n    sequence_len = hp.Int('sequence_len', min_value=64, max_value=128, step=16)\\n\\n    embedding_layer = Embedding(\\n        input_dim=vocab_size,\\n        output_dim=embedding_dim,\\n        input_length=sequence_len,\\n        weights=[trained_embeddings],\\n        trainable=False\\n    )\\n\\n    model.add(embedding_layer)\\n\\n    model.add(Flatten())\\n\\n    num_layers = hp.Int('num_layers', min_value=1, max_value=4)\\n\\n    for i in range(num_layers):\\n        model.add(Dense(\\n            units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=64, step=16),\\n            activation='tanh'\\n        ))\\n\\n    # Output layer\\n    model.add(Dense(1, activation='sigmoid'))  # Assuming 5 classes\\n\\n    optimizer = hp.Choice('optimizer', ['Adam', 'AdamW', 'SGD'])\\n\\n    if optimizer == 'Adam':\\n        opt = Adam(learning_rate=0.001)\\n    elif optimizer == 'AdamW':\\n        opt = AdamW(learning_rate=0.001)\\n    else:\\n        opt = SGD(learning_rate=0.001)\\n    model.compile(optimizer=opt, loss=BinaryFocalCrossentropy(), metrics=[macro_f1_score])\\n\\n    return model\\n\\nobjective = Objective('val_macro_f1_score', direction='max')\\n\\n# Hyperparameter search\\ntuner = RandomSearch(\\n    build_model,\\n    objective=objective,\\n    max_trials=15,\\n    executions_per_trial=1,\\n    directory='hyperparam_tuning',\\n    project_name='ffnn_tuning_v7.2213123123'\\n)\\n\\ntuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\\n\\nbest_model_ffnn = tuner.get_best_models(num_models=1)[0]\\nbest_model_ffnn.summary()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Function to build the FFNN model for tuning\n",
        "'''def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    embedding_dim = 100\n",
        "\n",
        "    sequence_len = hp.Int('sequence_len', min_value=64, max_value=128, step=16)\n",
        "\n",
        "    embedding_layer = Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        input_length=sequence_len,\n",
        "        weights=[trained_embeddings],\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    model.add(embedding_layer)\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    num_layers = hp.Int('num_layers', min_value=1, max_value=4)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=64, step=16),\n",
        "            activation='tanh'\n",
        "        ))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Assuming 5 classes\n",
        "\n",
        "    optimizer = hp.Choice('optimizer', ['Adam', 'AdamW', 'SGD'])\n",
        "\n",
        "    if optimizer == 'Adam':\n",
        "        opt = Adam(learning_rate=0.001)\n",
        "    elif optimizer == 'AdamW':\n",
        "        opt = AdamW(learning_rate=0.001)\n",
        "    else:\n",
        "        opt = SGD(learning_rate=0.001)\n",
        "    model.compile(optimizer=opt, loss=BinaryFocalCrossentropy(), metrics=[macro_f1_score])\n",
        "\n",
        "    return model\n",
        "\n",
        "objective = Objective('val_macro_f1_score', direction='max')\n",
        "\n",
        "# Hyperparameter search\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective=objective,\n",
        "    max_trials=15,\n",
        "    executions_per_trial=1,\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name='ffnn_tuning_v7.2213123123'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "best_model_ffnn = tuner.get_best_models(num_models=1)[0]\n",
        "best_model_ffnn.summary()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Saving the models**"
      ],
      "metadata": {
        "id": "E7-2_e8I6qCt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "IvRrrAXzrVoV"
      },
      "outputs": [],
      "source": [
        "# best_model_ffnn.save('best_model_ffnn.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the saved models**"
      ],
      "metadata": {
        "id": "X9OFtbJn6xR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_ffnn = tf.keras.models.load_model('best_model_ffnn.keras', custom_objects={'macro_f1_score': macro_f1_score})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btp5estysaLN",
        "outputId": "284e57ff-29dc-4477-f64c-c44f24f49c3a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "vW0aeQXwrVoV"
      },
      "outputs": [],
      "source": [
        "def print_macro_f1(classification_report_dict, model_name):\n",
        "    macro_f1 = classification_report_dict['macro avg']['f1-score']\n",
        "    print(f\"{model_name} Model Macro Average F1-score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing and Evaluation**"
      ],
      "metadata": {
        "id": "BFk0sGAZ66oH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGzqtOPnrVoV",
        "outputId": "ab8e6586-d5d5-4331-fe52-711f74f52634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "FFNN Model Macro Average F1-score: 0.4726\n"
          ]
        }
      ],
      "source": [
        "test_labels = test_data['Tag'].values\n",
        "\n",
        "models = {\n",
        "    \"FFNN\": best_model_ffnn,\n",
        "}\n",
        "\n",
        "reports = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "    report = classification_report(\n",
        "        test_labels,\n",
        "        predictions,\n",
        "        target_names=[0,1],\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "\n",
        "    reports[model_name] = report\n",
        "\n",
        "    print_macro_f1(report, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Humour"
      ],
      "metadata": {
        "id": "unHAuORqqubu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "05a0f968-acbf-43b3-d56f-de8786a928ed",
        "id": "plFZtc8rggNv"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                          Sentence  Tag\n",
              "1567                                    Misbah-ul-haq wants to make love.\\nSings, \"Misbahon ke darmiyan, do pyar mil rahe hain...\"    1\n",
              "1724                                                                        .@ashutosh83B bhai taiyaar ho jaa.. aaj tujhe jalaenge    1\n",
              "1519                                                                Koi baat nahi, Pakistan ki to maari thi na hum logo ne. Chill.    0\n",
              "956                                               Jamai Raja, Kumkum Bhagya, Diya Aur Baati Hum etc etc. \\n#ThingsThatUniteIndians    1\n",
              "912                                                                                         Raina usko mazza Chatara hai #IndvsZim    0\n",
              "1977            Ram Kapoor: Meri biwi mujhe bol rahi hai ki meri jaan le lo.\\n\\nAll married man: BHENCHO WHAT ARE YOU WAITING FOR?    1\n",
              "941                                                                                      Jee karda.. marjaniya.. #badlapur #OnLoop    0\n",
              "581                                                                           5 - 5 karke tamatar phenkopic.twitter.com/a55ucfBgZk    1\n",
              "634                                            Hahahahaha ab to gaali dene ka mann bhi nahi kar raha. Hasi aa rahi hai chutiyo pe     1\n",
              "276   Dhoni better make up for his decision making with his batting. Nahi to ghar ghar mein aaj Yograj Singh jaag uthega #IndvsPak    1\n",
              "1224                    \"Mein, Rocky, idhar udhar har ladki ke peeche bhaagta rehta hu.. Par mujhe apni pasand ki ladki nahi mili\"    0\n",
              "858   Maam @priyankac19 aap apna dimaag bank locker me mat rakha karo.. Weekend pe bank band rehta hai.. Ab Monday subah hi milega    1\n",
              "241                                                          Alia Bhatt playing Kya Aap Panchvi Pass Se Tez Hai\\n#FailedExperiment    1\n",
              "208                                                                      Yunhi tum mujhko RT karti ho, ya koi pyaar ka iraada hai?    1\n",
              "910                       Suno gaur se duniya walon\\nChahe jitne mahal bana lo\\nUske aage gate laga lo\\nUske aage honge hum Nepali    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfa50f91-79d4-4ad5-bbdc-0830557cb6fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1567</th>\n",
              "      <td>Misbah-ul-haq wants to make love.\\nSings, \"Misbahon ke darmiyan, do pyar mil rahe hain...\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>.@ashutosh83B bhai taiyaar ho jaa.. aaj tujhe jalaenge</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>Koi baat nahi, Pakistan ki to maari thi na hum logo ne. Chill.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>Jamai Raja, Kumkum Bhagya, Diya Aur Baati Hum etc etc. \\n#ThingsThatUniteIndians</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>Raina usko mazza Chatara hai #IndvsZim</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1977</th>\n",
              "      <td>Ram Kapoor: Meri biwi mujhe bol rahi hai ki meri jaan le lo.\\n\\nAll married man: BHENCHO WHAT ARE YOU WAITING FOR?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>Jee karda.. marjaniya.. #badlapur #OnLoop</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>5 - 5 karke tamatar phenkopic.twitter.com/a55ucfBgZk</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>Hahahahaha ab to gaali dene ka mann bhi nahi kar raha. Hasi aa rahi hai chutiyo pe</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>Dhoni better make up for his decision making with his batting. Nahi to ghar ghar mein aaj Yograj Singh jaag uthega #IndvsPak</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1224</th>\n",
              "      <td>\"Mein, Rocky, idhar udhar har ladki ke peeche bhaagta rehta hu.. Par mujhe apni pasand ki ladki nahi mili\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>Maam @priyankac19 aap apna dimaag bank locker me mat rakha karo.. Weekend pe bank band rehta hai.. Ab Monday subah hi milega</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>Alia Bhatt playing Kya Aap Panchvi Pass Se Tez Hai\\n#FailedExperiment</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>Yunhi tum mujhko RT karti ho, ya koi pyaar ka iraada hai?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>910</th>\n",
              "      <td>Suno gaur se duniya walon\\nChahe jitne mahal bana lo\\nUske aage gate laga lo\\nUske aage honge hum Nepali</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfa50f91-79d4-4ad5-bbdc-0830557cb6fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfa50f91-79d4-4ad5-bbdc-0830557cb6fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfa50f91-79d4-4ad5-bbdc-0830557cb6fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-734dd6bf-1c8e-48a5-9a61-a0d4a670c7ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-734dd6bf-1c8e-48a5-9a61-a0d4a670c7ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-734dd6bf-1c8e-48a5-9a61-a0d4a670c7ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Dhoni better make up for his decision making with his batting. Nahi to ghar ghar mein aaj Yograj Singh jaag uthega #IndvsPak\",\n          \"Maam @priyankac19 aap apna dimaag bank locker me mat rakha karo.. Weekend pe bank band rehta hai.. Ab Monday subah hi milega\",\n          \"Misbah-ul-haq wants to make love.\\nSings, \\\"Misbahon ke darmiyan, do pyar mil rahe hain...\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "train_data = pd.read_csv('/content/train.csv.1')\n",
        "test_data = pd.read_csv('/content/val.csv.1')\n",
        "\n",
        "texts = train_data['Sentence'].values\n",
        "labels = train_data['Tag'].values\n",
        "\n",
        "train_data.sample(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre-processing**"
      ],
      "metadata": {
        "id": "_0mrOt_nggNw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "jrBebPcsggNw"
      },
      "outputs": [],
      "source": [
        "texts_preprocessed = [preprocess_text(text) for text in texts]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts_preprocessed)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(texts_preprocessed)\n",
        "\n",
        "max_sequence_len = 128\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "0d42880b-32cb-4c16-8e9c-0cab475cedc0",
        "id": "E7mlABpVggNw"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'skipgrams = generate_skipgram_pairs(sentences, window_size, vocab_size)\\n\\nX_target, X_context = zip(*skipgrams)\\nX_target = np.array(X_target)\\nX_context = np.array(X_context)\\n\\ninput_target = tf.keras.layers.Input(shape=(1,))\\ninput_context = tf.keras.layers.Input(shape=(1,))\\n\\nembedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name=\"embedding\")\\ntarget_embedding = embedding(input_target)\\ncontext_embedding = embedding(input_context)\\n\\ntarget_embedding = tf.keras.layers.Reshape((embedding_dim,))(target_embedding)\\ncontext_embedding = tf.keras.layers.Reshape((embedding_dim,))(context_embedding)\\n\\ndot_product = tf.keras.layers.Dot(axes=1)([target_embedding, context_embedding])\\noutput = tf.keras.layers.Dense(1, activation=\\'sigmoid\\')(dot_product)\\n\\nword2vec_model = tf.keras.Model(inputs=[input_target, input_context], outputs=output)\\nword2vec_model.compile(optimizer=\\'adam\\', loss=\\'binary_crossentropy\\')\\n\\nlabels = np.ones((len(skipgrams), 1))  # Positive samples are labeled 1\\n\\nword2vec_model.fit([X_target, X_context], labels, epochs=10, batch_size=128)\\ntrained_embeddings = word2vec_model.get_layer(\\'embedding\\').get_weights()[0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "\n",
        "sentences = [text.split() for text in texts_preprocessed]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "embedding_dim = 100\n",
        "window_size = 5\n",
        "\n",
        "'''skipgrams = generate_skipgram_pairs(sentences, window_size, vocab_size)\n",
        "\n",
        "X_target, X_context = zip(*skipgrams)\n",
        "X_target = np.array(X_target)\n",
        "X_context = np.array(X_context)\n",
        "\n",
        "input_target = tf.keras.layers.Input(shape=(1,))\n",
        "input_context = tf.keras.layers.Input(shape=(1,))\n",
        "\n",
        "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name=\"embedding\")\n",
        "target_embedding = embedding(input_target)\n",
        "context_embedding = embedding(input_context)\n",
        "\n",
        "target_embedding = tf.keras.layers.Reshape((embedding_dim,))(target_embedding)\n",
        "context_embedding = tf.keras.layers.Reshape((embedding_dim,))(context_embedding)\n",
        "\n",
        "dot_product = tf.keras.layers.Dot(axes=1)([target_embedding, context_embedding])\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(dot_product)\n",
        "\n",
        "word2vec_model = tf.keras.Model(inputs=[input_target, input_context], outputs=output)\n",
        "word2vec_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "labels = np.ones((len(skipgrams), 1))  # Positive samples are labeled 1\n",
        "\n",
        "word2vec_model.fit([X_target, X_context], labels, epochs=10, batch_size=128)\n",
        "trained_embeddings = word2vec_model.get_layer('embedding').get_weights()[0]'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save('word2vec_embeddings1.npy', trained_embeddings)"
      ],
      "metadata": {
        "id": "2W3KQm_aggNx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "MCeqzl7TggNx"
      },
      "outputs": [],
      "source": [
        "# trained_embeddings = np.load('word2vec_embeddings1.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "y4HKvJxvggNx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fd978ad1-221a-4ffc-ce9e-de6a083318d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"X = pad_sequences(sequences, maxlen=max_sequence_len)\\nlabels = train_data['Tag'].values\\n\\nX_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.1, random_state=60)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "'''X = pad_sequences(sequences, maxlen=max_sequence_len)\n",
        "labels = train_data['Tag'].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.1, random_state=60)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4H3rYQupggNx"
      },
      "outputs": [],
      "source": [
        "test_texts = test_data['Sentence'].values\n",
        "test_texts_preprocessed = [preprocess_text(text) for text in test_texts]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts_preprocessed)\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_sequence_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "9VtNTyNyggNx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "outputId": "c63c99ff-4a4e-49a9-d4ab-f1565a21dcd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "9u6FdOizggNx"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def build_model(hp):\\n    model = Sequential()\\n\\n    embedding_dim = 100\\n\\n    sequence_len = hp.Int('sequence_len', min_value=64, max_value=128, step=16)\\n\\n    embedding_layer = Embedding(\\n        input_dim=vocab_size,\\n        output_dim=embedding_dim,\\n        input_length=sequence_len,\\n        weights=[trained_embeddings],\\n        trainable=False\\n    )\\n\\n    model.add(embedding_layer)\\n    model.add(Flatten())\\n\\n    num_layers = hp.Int('num_layers', min_value=1, max_value=4)\\n\\n    for i in range(num_layers):\\n        model.add(Dense(\\n            units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=64, step=16),\\n            activation='tanh'\\n        ))\\n\\n    model.add(Dense(1, activation='sigmoid'))\\n\\n    optimizer = hp.Choice('optimizer', ['Adam', 'AdamW', 'SGD'])\\n\\n    if optimizer == 'Adam':\\n        opt = Adam(learning_rate=0.001)\\n    elif optimizer == 'AdamW':\\n        opt = AdamW(learning_rate=0.001)\\n    else:\\n        opt = SGD(learning_rate=0.001)\\n\\n    model.compile(optimizer=opt, loss=BinaryFocalCrossentropy(), metrics=[macro_f1_score])\\n\\n    return model\\n\\nobjective = Objective('val_macro_f1_score', direction='max')\\n\\ntuner = RandomSearch(\\n    build_model,\\n    objective=objective,\\n    max_trials=15,\\n    executions_per_trial=1,\\n    directory='hyperparam_tuning2',\\n    project_name='ffnn_tuning_v7.2213123123'\\n)\\n\\ntuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\\nbest_model_ffnn = tuner.get_best_models(num_models=1)[0]\\nbest_model_ffnn.summary()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "'''def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    embedding_dim = 100\n",
        "\n",
        "    sequence_len = hp.Int('sequence_len', min_value=64, max_value=128, step=16)\n",
        "\n",
        "    embedding_layer = Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        input_length=sequence_len,\n",
        "        weights=[trained_embeddings],\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    model.add(embedding_layer)\n",
        "    model.add(Flatten())\n",
        "\n",
        "    num_layers = hp.Int('num_layers', min_value=1, max_value=4)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=64, step=16),\n",
        "            activation='tanh'\n",
        "        ))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = hp.Choice('optimizer', ['Adam', 'AdamW', 'SGD'])\n",
        "\n",
        "    if optimizer == 'Adam':\n",
        "        opt = Adam(learning_rate=0.001)\n",
        "    elif optimizer == 'AdamW':\n",
        "        opt = AdamW(learning_rate=0.001)\n",
        "    else:\n",
        "        opt = SGD(learning_rate=0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=BinaryFocalCrossentropy(), metrics=[macro_f1_score])\n",
        "\n",
        "    return model\n",
        "\n",
        "objective = Objective('val_macro_f1_score', direction='max')\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective=objective,\n",
        "    max_trials=15,\n",
        "    executions_per_trial=1,\n",
        "    directory='hyperparam_tuning2',\n",
        "    project_name='ffnn_tuning_v7.2213123123'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "best_model_ffnn = tuner.get_best_models(num_models=1)[0]\n",
        "best_model_ffnn.summary()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "-F6CoC1jggNx"
      },
      "outputs": [],
      "source": [
        "# best_model_ffnn.save('best_model_ffnn1.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_ffnn = tf.keras.models.load_model('best_model_ffnn1.keras', custom_objects={'macro_f1_score': macro_f1_score})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b580bdc4-7b7d-4585-94f5-9f03bacc7217",
        "id": "Oj40EPcJggNy"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283d84ce-4b7d-4907-a282-5805ea8c35dd",
        "id": "qWEQZDQdggNy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "FFNN Model Macro Average F1-score: 0.6228\n"
          ]
        }
      ],
      "source": [
        "test_labels = test_data['Tag'].values\n",
        "\n",
        "models = {\n",
        "    \"FFNN\": best_model_ffnn,\n",
        "}\n",
        "\n",
        "reports = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "    report = classification_report(\n",
        "        test_labels,\n",
        "        predictions,\n",
        "        target_names=[0,1],\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    reports[model_name] = report\n",
        "\n",
        "    print_macro_f1(report, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sarcasm**"
      ],
      "metadata": {
        "id": "iE-R1JYeq0_W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "61971f17-fd8a-4bfd-b03e-26684900d159",
        "id": "TeslvUBtq0_W"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                Sentence  Tag\n",
              "3771                                                                                                  Manoj ji ye aam aadmi hai logo ke liye apni politics to banati hai    0\n",
              "781                                                                                                 4 din me 2 accidents, kuch to jhol hai,shayad politics ho rahi hai..    0\n",
              "3065                           Ghotala kumar police ne arrest Kiya vo Nahi dekha??  Yahi mullavadi aur parivarvadi politics gart me gira rahi hai tum ko aur congress ko    0\n",
              "2471                                                                 Chutiyo ke chacha jan politics hi kahe nahi join kar lete Ashutoswa ki tarah kabhi saram ati hai ka    0\n",
              "2020                        Akhir tum  jaise qoum ke bewakoof kuch nahi karenge toh moulana ko yeh sab karna hi padega na politics hamare liye masla hai solve karna hai    0\n",
              "2162                                      @ShazaFK agr ap waiqi insaniyt  k liye #KPK gae ho to..... phir elaaj he kro.... ye elaaj k naam pe politics q kr rahay ho????    0\n",
              "2734                                                                                                             Nitish kumar ki gandi politics ab ek ek kr samne aayega    0\n",
              "3800  Abhi tak Hame cricket me out karne wala Paida bhi nahi hua hai agar Hame  agar koi cricket me out kar de usse 101 rupay Diya karate the pic.twitter.com/UJc2GtlfW8    0\n",
              "4075                                                                                          370 aur 35A hat kar rahegi , triple talaq ki tarah , kuchh bhi kar lo.....    0\n",
              "231                                                                                 Bhai @iamsrk ki Raees dekhne chalein? \"Bro paise nahi hain.\" #irony #Raees #MonthEnd    1\n",
              "1497                                                                                             ye sirf vote bank hai or kuch v nhi bjp dharm wali politics kr rahe hai    0\n",
              "2084                                                                                               Jab tak iss desh mein cricket hai, tab tak log chutiye bante rahenge.    0\n",
              "397                                #politics Nanga bhi our mehanga bhi hota hai .. @SadhguruJV @ishafoundation #Spirituality can hide any things  #india #SadhguruQuotes    0\n",
              "3704                                                                                              Khuda Tamam Khud Kash Hamla Awaron Ko Lambi Umar ataa karay - #Sarcasm    1\n",
              "964                                                        Abhi tak ye samajh main nahi aai triple talaq musalmano k liye ban lekin khush hindu and media ho rahain hain    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a77cc5a9-9aba-4dd4-94b5-8a17f99ba993\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3771</th>\n",
              "      <td>Manoj ji ye aam aadmi hai logo ke liye apni politics to banati hai</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>4 din me 2 accidents, kuch to jhol hai,shayad politics ho rahi hai..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3065</th>\n",
              "      <td>Ghotala kumar police ne arrest Kiya vo Nahi dekha??  Yahi mullavadi aur parivarvadi politics gart me gira rahi hai tum ko aur congress ko</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2471</th>\n",
              "      <td>Chutiyo ke chacha jan politics hi kahe nahi join kar lete Ashutoswa ki tarah kabhi saram ati hai ka</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020</th>\n",
              "      <td>Akhir tum  jaise qoum ke bewakoof kuch nahi karenge toh moulana ko yeh sab karna hi padega na politics hamare liye masla hai solve karna hai</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>@ShazaFK agr ap waiqi insaniyt  k liye #KPK gae ho to..... phir elaaj he kro.... ye elaaj k naam pe politics q kr rahay ho????</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2734</th>\n",
              "      <td>Nitish kumar ki gandi politics ab ek ek kr samne aayega</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3800</th>\n",
              "      <td>Abhi tak Hame cricket me out karne wala Paida bhi nahi hua hai agar Hame  agar koi cricket me out kar de usse 101 rupay Diya karate the pic.twitter.com/UJc2GtlfW8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4075</th>\n",
              "      <td>370 aur 35A hat kar rahegi , triple talaq ki tarah , kuchh bhi kar lo.....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>Bhai @iamsrk ki Raees dekhne chalein? \"Bro paise nahi hain.\" #irony #Raees #MonthEnd</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>ye sirf vote bank hai or kuch v nhi bjp dharm wali politics kr rahe hai</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2084</th>\n",
              "      <td>Jab tak iss desh mein cricket hai, tab tak log chutiye bante rahenge.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>#politics Nanga bhi our mehanga bhi hota hai .. @SadhguruJV @ishafoundation #Spirituality can hide any things  #india #SadhguruQuotes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3704</th>\n",
              "      <td>Khuda Tamam Khud Kash Hamla Awaron Ko Lambi Umar ataa karay - #Sarcasm</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>Abhi tak ye samajh main nahi aai triple talaq musalmano k liye ban lekin khush hindu and media ho rahain hain</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a77cc5a9-9aba-4dd4-94b5-8a17f99ba993')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a77cc5a9-9aba-4dd4-94b5-8a17f99ba993 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a77cc5a9-9aba-4dd4-94b5-8a17f99ba993');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb5ee7ac-51cd-45fe-89bb-a91f7c0d5f47\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb5ee7ac-51cd-45fe-89bb-a91f7c0d5f47')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb5ee7ac-51cd-45fe-89bb-a91f7c0d5f47 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Bhai @iamsrk ki Raees dekhne chalein? \\\"Bro paise nahi hain.\\\" #irony #Raees #MonthEnd\",\n          \"Jab tak iss desh mein cricket hai, tab tak log chutiye bante rahenge.\",\n          \"Manoj ji ye aam aadmi hai logo ke liye apni politics to banati hai\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "\n",
        "train_data = pd.read_csv('/content/train.csv.2')\n",
        "test_data = pd.read_csv('/content/val.csv.2')\n",
        "\n",
        "texts = train_data['Sentence'].values\n",
        "labels = train_data['Tag'].values\n",
        "\n",
        "train_data.sample(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing"
      ],
      "metadata": {
        "id": "pU_AqlOWq0_X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "8oDQ1BNHq0_X"
      },
      "outputs": [],
      "source": [
        "texts_preprocessed = [preprocess_text(text) for text in texts]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts_preprocessed)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(texts_preprocessed)\n",
        "\n",
        "max_sequence_len = 128\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "ed3fe082-823d-4d89-a28d-89dbe40b7eb3",
        "id": "QZv1W2ywq0_X"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'skipgrams = generate_skipgram_pairs(sentences, window_size, vocab_size)\\n\\nX_target, X_context = zip(*skipgrams)\\nX_target = np.array(X_target)\\nX_context = np.array(X_context)\\n\\ninput_target = tf.keras.layers.Input(shape=(1,))\\ninput_context = tf.keras.layers.Input(shape=(1,))\\n\\nembedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name=\"embedding\")\\ntarget_embedding = embedding(input_target)\\ncontext_embedding = embedding(input_context)\\n\\ntarget_embedding = tf.keras.layers.Reshape((embedding_dim,))(target_embedding)\\ncontext_embedding = tf.keras.layers.Reshape((embedding_dim,))(context_embedding)\\n\\ndot_product = tf.keras.layers.Dot(axes=1)([target_embedding, context_embedding])\\noutput = tf.keras.layers.Dense(1, activation=\\'sigmoid\\')(dot_product)\\n\\nword2vec_model = tf.keras.Model(inputs=[input_target, input_context], outputs=output)\\nword2vec_model.compile(optimizer=\\'adam\\', loss=\\'binary_crossentropy\\')\\n\\nlabels = np.ones((len(skipgrams), 1))\\nword2vec_model.fit([X_target, X_context], labels, epochs=10, batch_size=128)\\n\\ntrained_embeddings = word2vec_model.get_layer(\\'embedding\\').get_weights()[0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "\n",
        "sentences = [text.split() for text in texts_preprocessed]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "embedding_dim = 100\n",
        "window_size = 5\n",
        "\n",
        "'''skipgrams = generate_skipgram_pairs(sentences, window_size, vocab_size)\n",
        "\n",
        "X_target, X_context = zip(*skipgrams)\n",
        "X_target = np.array(X_target)\n",
        "X_context = np.array(X_context)\n",
        "\n",
        "input_target = tf.keras.layers.Input(shape=(1,))\n",
        "input_context = tf.keras.layers.Input(shape=(1,))\n",
        "\n",
        "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name=\"embedding\")\n",
        "target_embedding = embedding(input_target)\n",
        "context_embedding = embedding(input_context)\n",
        "\n",
        "target_embedding = tf.keras.layers.Reshape((embedding_dim,))(target_embedding)\n",
        "context_embedding = tf.keras.layers.Reshape((embedding_dim,))(context_embedding)\n",
        "\n",
        "dot_product = tf.keras.layers.Dot(axes=1)([target_embedding, context_embedding])\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(dot_product)\n",
        "\n",
        "word2vec_model = tf.keras.Model(inputs=[input_target, input_context], outputs=output)\n",
        "word2vec_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "labels = np.ones((len(skipgrams), 1))\n",
        "word2vec_model.fit([X_target, X_context], labels, epochs=10, batch_size=128)\n",
        "\n",
        "trained_embeddings = word2vec_model.get_layer('embedding').get_weights()[0]'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save('word2vec_embeddings2.npy', trained_embeddings)"
      ],
      "metadata": {
        "id": "bZcM33qlq0_X"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "jlUJrvONq0_X"
      },
      "outputs": [],
      "source": [
        "# trained_embeddings = np.load('word2vec_embeddings2.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "R74MaurAq0_X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8ff4dce2-684a-4e1c-f302-cab13918fdfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"X = pad_sequences(sequences, maxlen=max_sequence_len)\\nlabels = train_data['Tag'].values\\n\\nX_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.1, random_state=60)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "'''X = pad_sequences(sequences, maxlen=max_sequence_len)\n",
        "labels = train_data['Tag'].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.1, random_state=60)'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "48jvzqNYq0_Y"
      },
      "outputs": [],
      "source": [
        "test_texts = test_data['Sentence'].values\n",
        "test_texts_preprocessed = [preprocess_text(text) for text in test_texts]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts_preprocessed)\n",
        "X_test = pad_sequences(test_sequences, maxlen=max_sequence_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "92eOuzwYq0_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "outputId": "3b637a02-e174-4da9-df83-d92ce51c3963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "cMqd818wq0_Y"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def build_model(hp):\\n    model = Sequential()\\n\\n    embedding_dim = 100\\n    sequence_len = hp.Int('sequence_len', min_value=64, max_value=128, step=16)\\n    embedding_layer = Embedding(\\n        input_dim=vocab_size,\\n        output_dim=embedding_dim,\\n        input_length=sequence_len,\\n        weights=[trained_embeddings],\\n        trainable=False\\n    )\\n\\n    model.add(embedding_layer)\\n    model.add(Flatten())\\n    num_layers = hp.Int('num_layers', min_value=1, max_value=4)\\n\\n    for i in range(num_layers):\\n        model.add(Dense(\\n            units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=64, step=16),\\n            activation='tanh'\\n        ))\\n\\n    model.add(Dense(1, activation='sigmoid'))\\n\\n    optimizer = hp.Choice('optimizer', ['Adam', 'AdamW', 'SGD'])\\n\\n    if optimizer == 'Adam':\\n        opt = Adam(learning_rate=0.001)\\n    elif optimizer == 'AdamW':\\n        opt = AdamW(learning_rate=0.001)\\n    else:\\n        opt = SGD(learning_rate=0.001)\\n\\n    model.compile(optimizer=opt, loss=BinaryFocalCrossentropy(), metrics=[macro_f1_score])\\n\\n    return model\\n\\nobjective = Objective('val_macro_f1_score', direction='max')\\n\\ntuner = RandomSearch(\\n    build_model,\\n    objective=objective,\\n    max_trials=15,\\n    executions_per_trial=1,\\n    directory='hyperparam_tuning3',\\n    project_name='ffnn_tuning_v7.2213123123'\\n)\\n\\ntuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\\n\\nbest_model_ffnn = tuner.get_best_models(num_models=1)[0]\\n\\nbest_model_ffnn.summary()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "'''def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    embedding_dim = 100\n",
        "    sequence_len = hp.Int('sequence_len', min_value=64, max_value=128, step=16)\n",
        "    embedding_layer = Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        input_length=sequence_len,\n",
        "        weights=[trained_embeddings],\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    model.add(embedding_layer)\n",
        "    model.add(Flatten())\n",
        "    num_layers = hp.Int('num_layers', min_value=1, max_value=4)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'dense_units_{i+1}', min_value=32, max_value=64, step=16),\n",
        "            activation='tanh'\n",
        "        ))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = hp.Choice('optimizer', ['Adam', 'AdamW', 'SGD'])\n",
        "\n",
        "    if optimizer == 'Adam':\n",
        "        opt = Adam(learning_rate=0.001)\n",
        "    elif optimizer == 'AdamW':\n",
        "        opt = AdamW(learning_rate=0.001)\n",
        "    else:\n",
        "        opt = SGD(learning_rate=0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=BinaryFocalCrossentropy(), metrics=[macro_f1_score])\n",
        "\n",
        "    return model\n",
        "\n",
        "objective = Objective('val_macro_f1_score', direction='max')\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective=objective,\n",
        "    max_trials=15,\n",
        "    executions_per_trial=1,\n",
        "    directory='hyperparam_tuning3',\n",
        "    project_name='ffnn_tuning_v7.2213123123'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "best_model_ffnn = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "best_model_ffnn.summary()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "tUs5pyNBq0_Y"
      },
      "outputs": [],
      "source": [
        "# best_model_ffnn.save('best_model_ffnn2.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_ffnn = tf.keras.models.load_model('best_model_ffnn2.keras', custom_objects={'macro_f1_score': macro_f1_score})"
      ],
      "metadata": {
        "id": "T-zWUIq1q0_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb0acd9-7cd2-4ebe-9e1e-bbbea9cff759"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa195772-01be-4792-9125-9bf2bafa0b51",
        "id": "yAnr2JEcq0_Y"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "FFNN Model Macro Average F1-score: 0.7630\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_labels = test_data['Tag'].values\n",
        "\n",
        "models = {\n",
        "    \"FFNN\": best_model_ffnn,\n",
        "}\n",
        "\n",
        "reports = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "    report = classification_report(\n",
        "        test_labels,\n",
        "        predictions,\n",
        "        target_names=[0,1],\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    reports[model_name] = report\n",
        "\n",
        "    print_macro_f1(report, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T0e0IePDq0_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}